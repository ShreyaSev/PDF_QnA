{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53b8806",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/shreya/sem6/nlp/papers/qa_over_large_struct_doc.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c6944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(directory, extract_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f118065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(filename):\n",
    "    loader = PyPDFLoader(filename, extract_images=True)\n",
    "    pages = loader.load()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f97481",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_docs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52212990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3cbf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(documents) #to use across multiple documents rather than a string, use split_documents\n",
    "    return docs\n",
    "\n",
    "docs = split_docs(documents)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d148cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b717464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreya/anaconda3/envs/langchain/lib/python3.11/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad59e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db():\n",
    "    pinecone.init(\n",
    "    api_key=\"539e3f4e-1c1f-4894-a175-4d2abd5fbd31\",\n",
    "    environment=\"gcp-starter\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819d24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2195aa7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_index(index_name, dimension):\n",
    "    \n",
    "    if index_name in pinecone.list_indexes():\n",
    "        pinecone.delete_index(index_name)\n",
    "    \n",
    "    pinecone.create_index(name=index_name, metric=\"cosine\", dimension=dimension)\n",
    "    \n",
    "    index = Pinecone.from_documents(documents = docs, embedding=embeddings, index_name = index_name)\n",
    "    \n",
    "    return index\n",
    "\n",
    "DIMENSION = 4096\n",
    "index = create_index(\"langchain-pdfqna\", DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375ba4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40d76d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "retriever = index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "#prompt = PromptTemplate.from_template(\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84b21a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough #used to map input to keys in prompt \n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "contextualize_q_chain = contextualize_q_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f34c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def contextualized_question(input: dict):\n",
    "    if input.get(\"chat_history\"):\n",
    "        return contextualize_q_chain\n",
    "    else:\n",
    "        return input[\"question\"]\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=contextualized_question | retriever | format_docs\n",
    "    )\n",
    "    | qa_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42c9fc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, it appears that you are asking about PDF question answering. To answer this question, I can tell you that PDF question answering refers to the task of using natural language processing (NLP) techniques to extract relevant information from PDF documents. This can involve tasks such as identifying and extracting text, classifying the content of a document, or answering questions based on the contents of the document. The field of PDF question answering is a growing area of research, with applications in industries such as healthcare, finance, and legal.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "question = \"What is PDF question answering\"\n",
    "ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "print(ai_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c496ad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF question answering is used to extract relevant information from PDF documents for various purposes, such as:\n",
      "\n",
      "1. Automating document review and analysis: By using NLP techniques, PDF question answering can help automate the process of reviewing and analyzing large volumes of PDF documents, such as contracts, legal documents, or medical records.\n",
      "2. Improving document search and retrieval: PDF question answering can improve the accuracy and speed of document search and retrieval by allowing users to ask natural language questions about the contents of a document.\n",
      "3. Facilitating document-based decision-making: By providing relevant information from PDF documents, PDF question answering can help support decision-making processes by providing access to key data and insights.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages.ai import AIMessage\n",
    "chat_history.extend([HumanMessage(content=question), AIMessage(content = ai_msg)])\n",
    "\n",
    "second_question = \"Why is it used?\"\n",
    "ai_message = rag_chain.invoke({\"question\": second_question, \"chat_history\": chat_history})\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a105709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF question answering is a task that involves using natural language processing techniques to extract relevant information from PDF documents. This can include identifying and extracting text, classifying the content of a document, or answering questions based on the contents of the document. The field of PDF question answering is a growing area of research with applications in industries such as healthcare, finance, and legal."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream({\"question\":\"What is PDF question answering\", \"chat_history\":chat_history}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49da81d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Based on the context provided, it seems that you are asking about the pre-retrieval steps for PDF question answering. To answer this question, I can tell you that the pre-retrieval steps typically involve several activities, including:\n",
      "\n",
      "1. Document Preparation: The document is prepared by extracting relevant information, such as text, tables, and figures, into a structured format.\n",
      "2. Question Formulation: Annotators read the document and formulate questions based on the content of the document.\n",
      "3. Question Categorization: The formed questions are then categorized into different types based on their nature, such as Figure Questions, Text Questions, Table Reasoning, etc.\n",
      "4. Data Collection: The annotated questions are then collected and stored in a database for further analysis.-------------\n",
      "AI: Based on the context provided, it seems that you are asking about the pre-retrieval steps for PDF question answering. To answer this question, I can tell you that the pre-retrieval steps typically involve several activities, including:\n",
      "\n",
      "1. Document Preparation: The document is prepared by extracting relevant information, such as text, tables, and figures, into a structured format.\n",
      "2. Question Formulation: Annotators read the document and formulate questions based on the content of the document.\n",
      "3. Question Categorization: The formed questions are then categorized into different types based on their nature, such as Figure Questions, Text Questions, Table Reasoning, etc.\n",
      "4. Data Collection: The annotated questions are then collected and stored in a database for further analysis.\n"
     ]
    }
   ],
   "source": [
    "response = \"\"\n",
    "for chunk in rag_chain.stream({\"question\":\"What are the pre-retrieval steps?\", \"chat_history\":chat_history}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "    response+=chunk\n",
    "    \n",
    "print('-------------')\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain]",
   "language": "python",
   "name": "conda-env-langchain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
