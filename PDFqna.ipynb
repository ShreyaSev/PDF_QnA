{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53b8806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "directory = \"/home/shreya/sem6/nlp/papers/qa_over_large_struct_doc.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e6d2c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f118065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(filename):\n",
    "    pdfreader = PdfReader(directory)\n",
    "    # read text from pdf\n",
    "    raw_text = ''\n",
    "    for i, page in enumerate(pdfreader.pages):\n",
    "        content = page.extract_text()\n",
    "        if content:\n",
    "            raw_text += content\n",
    "            \n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f97481",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_docs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52212990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db3cbf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_text(documents) #to use across multiple documents rather than a string, use split_documents\n",
    "    return docs\n",
    "\n",
    "docs = split_docs(text)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d148cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42b09a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings.embed_query(\"Hello World\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b717464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2822726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=\"539e3f4e-1c1f-4894-a175-4d2abd5fbd31\",\n",
    "    environment=\"gcp-starter\"\n",
    ")\n",
    "\n",
    "index_name = \"langchain-pdfqna\"\n",
    "\n",
    "index = Pinecone.from_texts(texts = docs, embedding=embeddings, index_name = index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "694096fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similiar_docs(query, k=2, score=False):\n",
    "    if score:\n",
    "        similar_docs = index.similarity_search_with_score(query, k=k)\n",
    "    else:\n",
    "        similar_docs = index.similarity_search(query, k=k)\n",
    "    print(similar_docs)\n",
    "    \n",
    "    return similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "375ba4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37853d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d18344d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1448455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query):\n",
    "    similar_docs = get_similiar_docs(query)\n",
    "    answer = chain.run(input_documents=similar_docs, question=query)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "932098f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='the questions are primarily focused on document\\ncontents. The PDFTriage evaluation dataset seeksto expand on the question types in these datasets,\\ngetting questions that can reference the document\\nstructure or content, can be extractive or abstractive,\\nand can require long-form answers or rewrites.\\n3 PDFTriage: Structured Retrieval from\\nDocument Metadata\\nThePDFTriage approach consists of three steps to\\nanswer a user’s question, shown in Figure 1:\\n1.Generate document metadata (Sec. 3.1):\\nExtract the structural elements of a document\\nand convert them into readable metadata.\\n2.LLM-based triage (Sec. 3.2): Query the\\nLLM to select the precise content (pages, sec-\\ntions, retrieved content) from the document.\\n3.Answer using retrieved content (Sec. 3.3):\\nBased on the question and retrieved content,\\ngenerate an answer.# of Documents 82\\n# of Questions 908\\nEasy Questions 393\\nMedium Questions 144\\nHard Questions 266\\n“Unsure” Questions 105\\nTable 1: Dataset statistics for the PDFTriage evaluation'), Document(page_content='ing system. You answer questions by finding\\nrelevant content in the document and answer-\\ning questions based on that content.\\nDocument: <textual metadata of\\ndocument>\\nUsing user prompting, we then input the query\\nwith no additional formatting. Next, the PDFTriage\\nsystem uses the functions established in Section 2\\nto query the document for any necessary informa-\\ntion to answer the question. In each turn, PDF-\\nTriage uses a singular function to gather the needed\\ninformation before processing the retrieved context.\\nIn the final turn, the model outputs an answer to\\nthe question. For all of our experiments, we use the\\ngpt-35-turbo-0613 model.\\n4 Dataset Construction\\nTo test the efficacy of PDFTriage, we constructed a\\ndocument-focused set of question-answering tasks.\\nEach task seeks to evaluate different aspects of\\ndocument question-answering, analyzing reason-\\ning across text, tables, and figures within a docu-\\nment. Additionally, we wanted to create questions')]\n",
      "Based on the given context, I can provide information about PDF question answering.\n",
      "\n",
      "PDF question answering is a task that involves using a computer system to answer questions based on the content of a PDF document. The system uses various techniques, such as natural language processing (NLP) and machine learning (ML), to extract relevant information from the PDF and generate answers to the user's questions. The goal of PDF question answering is to provide accurate and informative responses to user queries by leveraging the structured data contained within the PDF document.\n",
      "\n",
      "The PDFTriage evaluation dataset provides a framework for evaluating the effectiveness of PDF question-answering systems, with 82 documents and 908 questions in total. The questions are categorized into easy, medium, hard, and \"unsure\" types, depending on their complexity and the amount of information required to answer them.\n",
      "\n",
      "To perform PDF question answering, the system typically involves three stages:\n",
      "\n",
      "1. Generating document metadata: This involves extracting structural elements from the PDF document, such as pages, sections, and retrieved content.\n",
      "2. LLM-based triage: The system queries a large language model (LLM) to identify the specific content within the PDF that is relevant to the user's question.\n",
      "3. Answer using retrieved content: Based on the question and the retrieved content, the system generates an answer to the user's query.\n",
      "\n",
      "The use of a large language model in the triage stage allows the system to quickly identify the most relevant parts of the PDF document for answering the user's question. The system then processes this information to generate an accurate response.\n",
      "\n",
      "In summary, PDF question answering is a task that involves using computer systems to answer questions based on the content of PDF documents. The process typically involves three stages: generating document metadata, querying a large language model, and answering the user's question using retrieved content.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is PDF question answering\"\n",
    "answer = get_answer(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b21a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain]",
   "language": "python",
   "name": "conda-env-langchain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
